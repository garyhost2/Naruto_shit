{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11580431,"sourceType":"datasetVersion","datasetId":7260990}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages\n!pip install ultralytics pyyaml split-folders --quiet","metadata":{"_uuid":"100dacf5-3760-4866-824e-3634f91f4b72","_cell_guid":"70f7990d-c484-4520-8bb2-ccf2ebd436db","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:31:22.238500Z","iopub.execute_input":"2025-04-26T21:31:22.238768Z","iopub.status.idle":"2025-04-26T21:32:38.043684Z","shell.execute_reply.started":"2025-04-26T21:31:22.238746Z","shell.execute_reply":"2025-04-26T21:32:38.042964Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport xml.etree.ElementTree as ET\nimport shutil\nimport splitfolders\nfrom IPython.display import FileLink\nfrom ultralytics import YOLO\nimport yaml","metadata":{"_uuid":"d3cabaf0-cc4c-44d5-9252-7fb1f50d3355","_cell_guid":"55a3df48-9940-48bc-bfb9-c686317037f8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:32:38.045184Z","iopub.execute_input":"2025-04-26T21:32:38.045455Z","iopub.status.idle":"2025-04-26T21:32:42.221170Z","shell.execute_reply.started":"2025-04-26T21:32:38.045435Z","shell.execute_reply":"2025-04-26T21:32:42.220617Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Define class mapping\nCLASS_MAPPING = {\n    'Horse': 0,\n    'Serpent': 1,\n    'Bird': 2,\n    'Boar': 3,\n    'Monkey': 4,\n    'Ox': 5,\n    'Ram': 6,\n    'Tiger': 7,\n    'Dog': 8,\n    'Dragon': 9,\n    'Hare': 10,\n    'Rat': 11\n}\n\n# Create YOLO directory structure\ndataset_dir = '/kaggle/working/dataset'\nos.makedirs(f'{dataset_dir}/images', exist_ok=True)\nos.makedirs(f'{dataset_dir}/labels', exist_ok=True)","metadata":{"_uuid":"5c925526-35da-434d-9795-2b2d48bbb737","_cell_guid":"4acafa37-4a60-4c2a-9864-76882cb69294","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:32:42.221836Z","iopub.execute_input":"2025-04-26T21:32:42.222110Z","iopub.status.idle":"2025-04-26T21:32:42.227017Z","shell.execute_reply.started":"2025-04-26T21:32:42.222094Z","shell.execute_reply":"2025-04-26T21:32:42.226361Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def convert_xml_to_yolo(xml_path, output_dir):\n    \"\"\"Convert PASCAL VOC XML to YOLO format txt files\"\"\"\n    tree = ET.parse(xml_path)\n    root = tree.getroot()\n    \n    # Get image dimensions\n    size = root.find('size')\n    width = int(size.find('width').text)\n    height = int(size.find('height').text)\n    \n    # Create label file\n    txt_file = os.path.join(output_dir, os.path.splitext(os.path.basename(xml_path))[0] + '.txt')\n    \n    with open(txt_file, 'w') as f:\n        for obj in root.iter('object'):\n            class_name = obj.find('name').text\n            if class_name not in CLASS_MAPPING:\n                continue  # Skip unknown classes\n                \n            cls = CLASS_MAPPING[class_name]\n            \n            # Get bounding box coordinates\n            bndbox = obj.find('bndbox')\n            xmin = int(bndbox.find('xmin').text)\n            ymin = int(bndbox.find('ymin').text)\n            xmax = int(bndbox.find('xmax').text)\n            ymax = int(bndbox.find('ymax').text)\n            \n            # Convert to YOLO format (center x, center y, width, height)\n            x_center = ((xmin + xmax) / 2) / width\n            y_center = ((ymin + ymax) / 2) / height\n            w = (xmax - xmin) / width\n            h = (ymax - ymin) / height\n            \n            f.write(f\"{cls} {x_center} {y_center} {w} {h}\\n\")","metadata":{"_uuid":"5b8e9bab-efa2-4720-8e21-6a70fc7ed05d","_cell_guid":"02e39882-0865-4959-b84d-ac5c7dda3daf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:32:42.227854Z","iopub.execute_input":"2025-04-26T21:32:42.228025Z","iopub.status.idle":"2025-04-26T21:32:42.250641Z","shell.execute_reply.started":"2025-04-26T21:32:42.228010Z","shell.execute_reply":"2025-04-26T21:32:42.250039Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Process all images and annotations\ninput_dir = '/kaggle/input/naruto-shity-data/Images'\n\nfor filename in os.listdir(input_dir):\n    if filename.endswith('.xml'):\n        xml_path = os.path.join(input_dir, filename)\n        img_name = os.path.splitext(filename)[0] + '.jpg'\n        img_path = os.path.join(input_dir, img_name)\n        \n        # Copy image if exists\n        if os.path.exists(img_path):\n            shutil.copy(img_path, f'{dataset_dir}/images/{img_name}')\n            # Convert and save label\n            convert_xml_to_yolo(xml_path, f'{dataset_dir}/labels')","metadata":{"_uuid":"c3d37876-51f5-465e-8c2e-6f669bf9de9c","_cell_guid":"19885777-d0b0-4f73-8d8c-3b2508300d0a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:32:42.252516Z","iopub.execute_input":"2025-04-26T21:32:42.252733Z","iopub.status.idle":"2025-04-26T21:32:43.129848Z","shell.execute_reply.started":"2025-04-26T21:32:42.252717Z","shell.execute_reply":"2025-04-26T21:32:43.129055Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Split dataset (80% train, 20% validation)\nsplitfolders.ratio(\n    dataset_dir,\n    output=\"/kaggle/working/split_dataset\",\n    seed=42,\n    ratio=(0.8, 0.2),\n    group_prefix=None,\n    move=False\n)","metadata":{"_uuid":"2093c0b3-e44a-4c2e-9581-11131a5bddc1","_cell_guid":"2e85c2c0-deb4-4895-9a38-8934878cccd0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:32:43.130694Z","iopub.execute_input":"2025-04-26T21:32:43.131556Z","iopub.status.idle":"2025-04-26T21:32:43.178098Z","shell.execute_reply.started":"2025-04-26T21:32:43.131533Z","shell.execute_reply":"2025-04-26T21:32:43.177511Z"}},"outputs":[{"name":"stderr","text":"Copying files: 232 files [00:00, 5934.13 files/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Create dataset.yaml\nyaml_content = \"\"\"\npath: /kaggle/working/split_dataset\ntrain: train/images\nval: val/images\nnames:\n  0: Horse\n  1: Serpent\n  2: Bird\n  3: Boar\n  4: Monkey\n  5: Ox\n  6: Ram\n  7: Tiger\n  8: Dog\n  9: Dragon\n  10: Hare\n  11: Rat\n\"\"\"\n\nwith open('/kaggle/working/dataset.yaml', 'w') as f:\n    f.write(yaml_content.strip())","metadata":{"_uuid":"3f08b1b5-8e5d-43d5-b7c0-c33a399d27c3","_cell_guid":"cb3e386b-a6c7-4cd3-9fa3-9ec255704775","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:35:16.146473Z","iopub.execute_input":"2025-04-26T21:35:16.147145Z","iopub.status.idle":"2025-04-26T21:35:16.151373Z","shell.execute_reply.started":"2025-04-26T21:35:16.147122Z","shell.execute_reply":"2025-04-26T21:35:16.150654Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Initialize YOLOv8 model (using larger model for better multi-class performance)\nmodel = YOLO('yolov8m.pt')  # Using medium version for better accuracy","metadata":{"_uuid":"09a56c46-6b83-4fb6-b8c6-81e84884edb1","_cell_guid":"3ae03367-de74-4d93-9559-f3e33a0b45a8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:32:46.286526Z","iopub.execute_input":"2025-04-26T21:32:46.286796Z","iopub.status.idle":"2025-04-26T21:32:50.400549Z","shell.execute_reply.started":"2025-04-26T21:32:46.286767Z","shell.execute_reply":"2025-04-26T21:32:50.399651Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 49.7M/49.7M [00:02<00:00, 24.5MB/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Train the model with adjusted parameters for multi-class\nresults = model.train(\n    data='/kaggle/working/dataset.yaml',\n    epochs=10,  # Increased epochs for better convergence\n    batch=16,\n    imgsz=640,\n    device=0,\n    project='/kaggle/working/results',\n    name='naruto_signs',\n    optimizer='AdamW',  # Better for multi-class\n    lr0=0.001,\n    patience=20,  # Increased patience\n    weight_decay=0.0005,\n    hsv_h=0.015,  # Color augmentation\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=10,  # Rotation augmentation\n    flipud=0.5,  # Vertical flip\n    fliplr=0.5   # Horizontal flip\n)","metadata":{"_uuid":"d8f64f7e-6e38-4015-a7fa-ef4736745263","_cell_guid":"b7058516-24e1-444c-aef0-7d74d56504ff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:36:15.030518Z","iopub.execute_input":"2025-04-26T21:36:15.031161Z","iopub.status.idle":"2025-04-26T21:37:21.406900Z","shell.execute_reply.started":"2025-04-26T21:36:15.031133Z","shell.execute_reply":"2025-04-26T21:37:21.405937Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.118 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/kaggle/working/dataset.yaml, epochs=10, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=/kaggle/working/results, name=naruto_signs3, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=/kaggle/working/results/naruto_signs3\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3782644  ultralytics.nn.modules.head.Detect           [12, [192, 384, 576]]         \nModel summary: 169 layers, 25,863,268 parameters, 25,863,252 gradients, 79.1 GFLOPs\n\nTransferred 475/475 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2304.3±611.7 MB/s, size: 84.3 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/split_dataset/train/labels.cache... 92 images, 0 backgrounds, 0 corrupt: 100%|██████████| 92/92 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1159.5±356.4 MB/s, size: 81.2 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/split_dataset/val/labels.cache... 24 images, 0 backgrounds, 0 corrupt: 100%|██████████| 24/24 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to /kaggle/working/results/naruto_signs3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/results/naruto_signs3\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/10      12.1G      1.343      2.753      1.698         12        640: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.354      0.636      0.358      0.164\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/10        12G      1.316      2.626      1.616         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.576      0.379      0.413      0.212\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/10      12.2G      1.446       2.05      1.713         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.589      0.459        0.5      0.295\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/10      12.5G      1.292      1.655      1.522         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.574      0.591      0.617      0.418\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/10      12.5G      1.167      1.416      1.475         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.491       0.58      0.591      0.396\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/10      12.5G      1.137      1.433       1.42         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.775      0.536      0.625      0.363\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/10      12.5G        1.1      1.006      1.303         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.552      0.455      0.529      0.299\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/10      12.5G      1.141      1.154      1.403         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.751      0.781      0.974      0.678\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/10      12.5G      1.098     0.9321      1.353         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24       0.83      0.868      0.995      0.716\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/10      12.2G     0.9681     0.9012      1.281         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.848      0.876      0.995      0.724\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n10 epochs completed in 0.015 hours.\nOptimizer stripped from /kaggle/working/results/naruto_signs3/weights/last.pt, 52.0MB\nOptimizer stripped from /kaggle/working/results/naruto_signs3/weights/best.pt, 52.0MB\n\nValidating /kaggle/working/results/naruto_signs3/weights/best.pt...\nUltralytics 8.3.118 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 92 layers, 25,846,708 parameters, 0 gradients, 78.7 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all         24         24      0.849      0.876      0.995      0.724\n                 Horse          1          1      0.763          1      0.995      0.895\n               Serpent          2          2          1          0      0.995      0.483\n                  Bird          2          2      0.548          1      0.995      0.821\n                  Boar          4          4      0.932          1      0.995      0.555\n                Monkey          1          1      0.895          1      0.995      0.796\n                    Ox          2          2          1      0.641      0.995      0.799\n                   Ram          3          3      0.488          1      0.995      0.553\n                 Tiger          3          3      0.955          1      0.995      0.713\n                   Dog          2          2      0.897          1      0.995      0.722\n                Dragon          3          3      0.953          1      0.995      0.831\n                   Rat          1          1      0.906          1      0.995      0.796\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.1ms preprocess, 8.8ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/results/naruto_signs3\u001b[0m\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Export best model\nbest_model = '/kaggle/working/results/naruto_signs3/weights/best.pt'\nshutil.copy(best_model, '/kaggle/working/best_naruto_signs.pt')\n\n# Create downloadable link\nFileLink('/kaggle/working/best_naruto_signs.pt')","metadata":{"_uuid":"b2ab0cab-381e-4ca8-b32f-a1f03bdd2505","_cell_guid":"64ef97da-8cfa-489e-8f92-1f280a8bf3da","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:38:45.590937Z","iopub.execute_input":"2025-04-26T21:38:45.591258Z","iopub.status.idle":"2025-04-26T21:38:45.636031Z","shell.execute_reply.started":"2025-04-26T21:38:45.591232Z","shell.execute_reply":"2025-04-26T21:38:45.635424Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_naruto_signs.pt","text/html":"<a href='/kaggle/working/best_naruto_signs.pt' target='_blank'>/kaggle/working/best_naruto_signs.pt</a><br>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Verification test with class labels\ntest_model = YOLO('/kaggle/working/best_naruto_signs.pt')\n\n# Get class names from YAML\nwith open('/kaggle/working/dataset.yaml') as f:\n    data = yaml.safe_load(f)\n    class_names = data['names']\n\nresults = test_model.predict(\n    source='/kaggle/working/split_dataset/val/images',\n    save=True,\n    conf=0.5,\n    line_thickness=2,\n    show_labels=True,\n    show_conf=True\n)\n\n# Display class distribution in validation set\nprint(\"\\nClass distribution in validation set:\")\nfor i, name in class_names.items():\n    count = len([r for r in results if int(r.boxes.cls[0]) == int(i)])\n    print(f\"{name}: {count} detections\")","metadata":{"_uuid":"6d248c82-8acd-46fb-9654-616d7c030074","_cell_guid":"4a4de921-91e7-4fef-a8fc-fc63c8c911f3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-26T21:39:35.621282Z","iopub.execute_input":"2025-04-26T21:39:35.621573Z","iopub.status.idle":"2025-04-26T21:39:36.628850Z","shell.execute_reply.started":"2025-04-26T21:39:35.621552Z","shell.execute_reply":"2025-04-26T21:39:36.628318Z"}},"outputs":[{"name":"stdout","text":"WARNING ⚠️ 'line_thickness' is deprecated and will be removed in in the future. Use 'line_width' instead.\n\nimage 1/24 /kaggle/working/split_dataset/val/images/Bird.20fa2833-da6c-11ec-a6e5-9cfce8f20ad4.jpg: 480x640 1 Bird, 42.6ms\nimage 2/24 /kaggle/working/split_dataset/val/images/Bird.23fac499-da6c-11ec-9117-9cfce8f20ad4.jpg: 480x640 1 Bird, 13.9ms\nimage 3/24 /kaggle/working/split_dataset/val/images/Boar.3ca7088d-dff3-11ec-ae62-9cfce8f20ad4.jpg: 480x640 1 Boar, 13.8ms\nimage 4/24 /kaggle/working/split_dataset/val/images/Boar.3f14da29-dff3-11ec-a1ed-9cfce8f20ad4.jpg: 480x640 1 Boar, 1 Tiger, 13.9ms\nimage 5/24 /kaggle/working/split_dataset/val/images/Boar.404b946f-dff3-11ec-a9dd-9cfce8f20ad4.jpg: 480x640 1 Boar, 1 Tiger, 13.9ms\nimage 6/24 /kaggle/working/split_dataset/val/images/Boar.43f0a86b-dff3-11ec-af36-9cfce8f20ad4.jpg: 480x640 1 Boar, 13.6ms\nimage 7/24 /kaggle/working/split_dataset/val/images/Dog.295189b0-dff6-11ec-a1a6-9cfce8f20ad4.jpg: 480x640 1 Dog, 13.5ms\nimage 8/24 /kaggle/working/split_dataset/val/images/Dog.2a8792fc-dff6-11ec-aaa2-9cfce8f20ad4.jpg: 480x640 1 Dog, 13.5ms\nimage 9/24 /kaggle/working/split_dataset/val/images/Dragon.1c0b6513-da85-11ec-9033-9cfce8f20ad4.jpg: 480x640 1 Dragon, 13.5ms\nimage 10/24 /kaggle/working/split_dataset/val/images/Dragon.2209e452-da85-11ec-91e8-9cfce8f20ad4.jpg: 480x640 1 Dragon, 13.4ms\nimage 11/24 /kaggle/working/split_dataset/val/images/Dragon.3bf44a1a-da85-11ec-a5e7-9cfce8f20ad4.jpg: 480x640 1 Dragon, 13.3ms\nimage 12/24 /kaggle/working/split_dataset/val/images/Horse.aa0728f3-da85-11ec-a305-9cfce8f20ad4.jpg: 480x640 2 Horses, 13.4ms\nimage 13/24 /kaggle/working/split_dataset/val/images/Monkey.e3bec027-da85-11ec-9c7f-9cfce8f20ad4.jpg: 480x640 1 Monkey, 12.8ms\nimage 14/24 /kaggle/working/split_dataset/val/images/Ox.3e2a1515-da86-11ec-858a-9cfce8f20ad4.jpg: 480x640 1 Tiger, 12.9ms\nimage 15/24 /kaggle/working/split_dataset/val/images/Ox.60dca0e0-da86-11ec-8e90-9cfce8f20ad4.jpg: 480x640 1 Ox, 12.9ms\nimage 16/24 /kaggle/working/split_dataset/val/images/Ram.efd15272-dab4-11ec-aa5d-9cfce8f20ad4.jpg: 480x640 1 Ram, 12.9ms\nimage 17/24 /kaggle/working/split_dataset/val/images/Ram.f4adc1d6-dab4-11ec-986d-9cfce8f20ad4.jpg: 480x640 1 Ram, 12.8ms\nimage 18/24 /kaggle/working/split_dataset/val/images/Ram.fab922c7-dab4-11ec-8243-9cfce8f20ad4.jpg: 480x640 1 Ram, 12.7ms\nimage 19/24 /kaggle/working/split_dataset/val/images/Rat.c1759e4b-da86-11ec-9915-9cfce8f20ad4.jpg: 480x640 1 Rat, 12.8ms\nimage 20/24 /kaggle/working/split_dataset/val/images/Serpant.54326bec-daa1-11ec-b2a9-9cfce8f20ad4.jpg: 480x640 1 Bird, 12.8ms\nimage 21/24 /kaggle/working/split_dataset/val/images/Serpant.590d5989-daa1-11ec-b727-9cfce8f20ad4.jpg: 480x640 1 Serpent, 1 Bird, 12.8ms\nimage 22/24 /kaggle/working/split_dataset/val/images/Tiger.61a88770-daa1-11ec-b61a-9cfce8f20ad4.jpg: 480x640 1 Ram, 1 Tiger, 12.7ms\nimage 23/24 /kaggle/working/split_dataset/val/images/Tiger.67bb5fce-daa1-11ec-b336-9cfce8f20ad4.jpg: 480x640 1 Ram, 1 Tiger, 12.8ms\nimage 24/24 /kaggle/working/split_dataset/val/images/Tiger.68f2057b-daa1-11ec-aa41-9cfce8f20ad4.jpg: 480x640 1 Ram, 1 Tiger, 12.7ms\nSpeed: 1.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nClass distribution in validation set:\nHorse: 1 detections\nSerpent: 1 detections\nBird: 3 detections\nBoar: 4 detections\nMonkey: 1 detections\nOx: 1 detections\nRam: 6 detections\nTiger: 1 detections\nDog: 2 detections\nDragon: 3 detections\nHare: 0 detections\nRat: 1 detections\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}